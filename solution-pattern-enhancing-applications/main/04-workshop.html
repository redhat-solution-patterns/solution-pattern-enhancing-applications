<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Enhancing Applications with Application Services :: Solution Patterns for Cloud Native Architectures</title>
    <link rel="prev" href="03-demo.html">
    <meta name="generator" content="Antora 3.0.0">
    <link rel="stylesheet" href="../../_/css/site.css">
<link rel="icon" href="../../_/img/favicon.ico" type="image/x-icon">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-H3CL05C7LX"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-H3CL05C7LX');
</script>  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://redhat.com" target="_blank"><img
          src="../../_/img/logo.png" height="40px" alt="Cloud Native Architecture Solution Patterns"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../..">Solution Patterns for Cloud Native Architectures</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">

       
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Solution Patterns</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Adopt Change Data Capture for <br/>stack modernization</a>
            <a class="navbar-item" href="#">Edge-to-Cloud Pipelines</a>     <a class="navbar-item" href="#">Event driven architecture</a>
          </div>
        </div>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Other</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://redhat-gitops-patterns.io/">GitOps Solution Patterns</a>
            <a class="navbar-item" href="https://hybrid-cloud-patterns.io/">Hybrid Cloud Solution Patterns</a>
          </div>
        </div>

        <a class="navbar-item" target="_blank" href="https://www.redhat.com/en/products/middleware">Red Hat Application Services</a>

        <a class="navbar-item" target="_blank" href="https://developers.redhat.com/middleware">Learn more</a>

      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="solution-pattern-enhancing-applications" data-version="main">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html" class=" query-params-link">Enhancing Applications with Application Services</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">1. Home page</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#content_overview">1.1 Content Overview</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#use-cases">1.2 Use cases</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="01-pattern.html#background">1.3 The story behind this solution pattern</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="01-pattern.html#solution">1.4 The solution</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="index.html#_explore_more_solution_patterns">1.5 Explore more solution patterns</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="02-architecture.html">2. Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#challenges">2.1. Common challenges</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#tech_stack">2.2. Technology stack</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#in_depth">2.3. An in-depth look at the solution&#8217;s architecture</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="02-architecture.html#more_tech">2.4. More about the technology stack</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="03-demo.html">3. See the Solution in Action</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="03-demo.html#demo">3.1. Recorded demo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="03-demo.html#demowalkthrough">3.2. Walkthrough guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="03-demo.html#_before_getting_started">3.3. Prerequisites</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="03-demo.html#_step_by_step_guide">3.4. Step by step guide</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="03-demo.html#_api_first_approach">API First approach</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="03-demo.html#_managed_apache_kafka_cloud_service">Managed Apache Kafka Cloud Service</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="03-demo.html#_inner_development_loop">Inner Development Loop</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="03-demo.html#_managed_api_management_cloud_service">Managed API Management Cloud Service</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item is-current-page" data-depth="1">
    <a class="nav-link" href="04-workshop.html">4. Workshop</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="https://redhat-solution-patterns.github.io/">5. Other Red Hat Solution Patterns</a>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Enhancing Applications with Application Services</span>
    <span class="version">main</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Enhancing Applications with Application Services</span>
      <ul class="versions">
        <li class="version is-current">
          <a href="index.html">main</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Enhancing Applications with Application Services</a></li>
    <li><a href="04-workshop.html">4. Workshop</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="https://github.com/redhat-solution-patterns/solution-pattern-enhancing-applications/edit/main/documentation/modules/ROOT/pages/04-workshop.adoc">Edit this Page</a></div>
  </div>
  <div class="content">
<article class="doc">
<h1 class="page">Enhancing Applications with Application Services</h1>
<h1 id="_workshop" class="sect0"><a class="anchor" href="#_workshop"></a><a class="link" href="#_workshop">Workshop</a></h1>
<div class="sect1">
<h2 id="_adding_event_streaming_capabilities_to_an_application"><a class="anchor" href="#_adding_event_streaming_capabilities_to_an_application"></a><a class="link" href="#_adding_event_streaming_capabilities_to_an_application">1. Adding Event Streaming capabilities to an application</a></h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_introduction"><a class="anchor" href="#_introduction"></a><a class="link" href="#_introduction">1.1. Introduction</a></h3>
<div class="paragraph">
<p>To support the business requirement of capturing and processing user activity on the Globex Coolstuff application, two new services have been developed:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Activity Tracking service: This service exposes a REST endpoint. User activities on the Coolstuff website (such as opening a product page, liking a product etc..) generates an activity payload which is sent to the Activity tracking REST endpoint. The service transforms this payload into a Kafka message which is sent to a topic on the Kafka broker.</p>
</li>
<li>
<p>Recommendation Engine: This service consumes and processes the events produced by the Activity Tracking service. The service uses the Kafka Streams library to continuously determine the top featured products (the products which generate the most activities).
The service also exposes a REST endpoint to expose the list of featured products.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Both services are developed using Quarkus and the Quarkus extensions for reactive messaging and Kafka Streams. The development of the services is outside the scope of this workshop, but you are encouraged to examine the source code of the applications on GitHub: <a href="https://https://github.com/app-modernization-workshop-globex/activity-tracking-service">Activity Tracking Service</a> and <a href="https://github.com/app-modernization-workshop-globex/recommendation-engine">Recommendation Engine</a></p>
</div>
<div class="paragraph">
<p>For the Kafka platform, the workshop uses Red Hat OpenShift Streams for Apache Kafka. OpenShift Streams for Apache Kafka is a fully hosted and managed Kafka cloud service. The service fulfills the requirement of Globex to avoid having to install and maintain a streaming platform. The service can be very easily consumed and used by developers.</p>
</div>
<div class="paragraph">
<p>In this workshop, you use <a href="https://servicebinding.io/">Service Binding For Kubernetes</a>. Service Binding allows you to communicate connection details and secrets to an application to allow it to bind to a service. In this context, a service can be anything: a Kafka instance, a NoSQL database, etc. By using Service Binding, we no longer need to configure connection details (host, port), authentication mechanisms (SASL, OAuth) and credentials (username/password, client id/client secret) in an application. Instead, Service Binding injects these variables into your application container (as files or environment variables) for your application to consume. The Quarkus Kubernetes Service Binding extension enables Quarkus applications to automatically pickup these variables, injected as files, from the container&#8217;s filesystem, removing the need to specify any configuration settings in the application resources (e.g configuration files) themselves.</p>
</div>
</div>
<div class="sect2">
<h3 id="_activities"><a class="anchor" href="#_activities"></a><a class="link" href="#_activities">1.2. Activities</a></h3>
<div class="paragraph">
<p>In this part of the workshop you will:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Provision and configure an OpenShift Streams for Apache Kafka instance.</p>
</li>
<li>
<p>Connect the Activity Tracking and Recommendation Engine applications to the OpenShift Streams for Apache Kafka instance using <a href="https://docs.openshift.com/container-platform/4.10/applications/connecting_applications_to_services/understanding-service-binding-operator.html">Service Binding</a>.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_environment_and_prerequisites"><a class="anchor" href="#_environment_and_prerequisites"></a><a class="link" href="#_environment_and_prerequisites">1.3. Environment and prerequisites</a></h3>
<div class="paragraph">
<p>The Globex Coolstuff application is deployed on an OpenShift cluster in a separate namespace. All activities in this part of the workshop can be done in the OpenShift console and do not require any tools to be installed on your workstation. However, the setup and the configuration of the Streams for Apache Kafka instance as well as the service binding can also be done using the Red Hat OpenShift Application Services (<code>rhoas</code>) CLI. Instructions for completing the workshop using the <code>rhoas</code> CLI can be found in the appendix at the end of the instructions.</p>
</div>
<div class="paragraph">
<p>Prerequisites:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>A Red Hat Account</p>
</li>
<li>
<p>Optional: <code>rhoas</code> and <code>oc</code> CLI installed on your workstation.</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_step_by_step_instructions"><a class="anchor" href="#_step_by_step_instructions"></a><a class="link" href="#_step_by_step_instructions">1.4. Step-By-Step Instructions</a></h3>
<div class="sect3">
<h4 id="_explore_the_environment"><a class="anchor" href="#_explore_the_environment"></a><a class="link" href="#_explore_the_environment">1.4.1. Explore the environment</a></h4>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>In a browser window, navigate to the console of your OpenShift cluster. Open the <strong>Developer</strong> perspective in the <strong>globex</strong> namespace.</p>
</li>
<li>
<p>In the Developer perspective, open the <strong>Topology</strong> view. Expect to see something like this (rearrange the topology as you see fit):</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/globex-deployment-topology.png" alt="globex deployment topology">
</div>
</div>
<div class="paragraph">
<p>The deployed topology consists of:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>globex-ui</code>: The Globex Coolstuff web application (Node.js/Angular).</p>
</li>
<li>
<p><code>catalog-app</code>: The Globex Coolstuff catalog service, consisting of the catalog database and the Spring Boot catalog microservice.</p>
</li>
<li>
<p><code>inventory-app</code>: The Globex Coolstuff inventory service, consisting of the inventory database and the Quarkus inventory microservice.</p>
</li>
<li>
<p><code>activity-tracking</code>: The Activity Tracking service. Notice that the deployment of the service is scaled to zero. The service will be scaled up once the connection to the Kafka broker is set up.</p>
</li>
<li>
<p><code>recommendation-engine</code>: The Recommendation Engine service. Notice that the deployment of the service is scaled to zero. The service will be scaled up once the connection to the Kafka broker is set up.</p>
</li>
<li>
<p><code>activity-tracking-simulator</code>: A Quarkus service that simulates user activity events and sends them to the Activity Tracking service.</p>
</li>
</ul>
</div>
</li>
<li>
<p>Find the route to the <strong>Globex UI</strong> application and open the URL in your browser.. Expect to see the home page of the Globex Coolstuff web application:</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/globex-coolstuff-home-page.png" alt="globex coolstuff home page">
</div>
</div>
<div class="paragraph">
<p>Click on <strong>Cool Stuff Store</strong> in the top menu to see a paginated list of products:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/04/globex-coolstuff-product-page.png" alt="globex coolstuff product page">
</div>
</div>
<div class="paragraph">
<p>Note the <em>Featured</em> pane on the home page, which is empty at the moment. Also the product list page has an empty bar above the product list. These elements will be populated once the recommendation engine is up and running.</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_provision_and_configure_a_streams_for_apache_kafka_instance"><a class="anchor" href="#_provision_and_configure_a_streams_for_apache_kafka_instance"></a><a class="link" href="#_provision_and_configure_a_streams_for_apache_kafka_instance">1.4.2. Provision and configure a Streams for Apache Kafka instance</a></h4>
<div class="paragraph">
<p>In this step you provision a Streams for Apache Kafka instance and create a topic for the activity tracking events.</p>
</div>
<div class="paragraph">
<p>The instructions use the Red Hat Hybrid Cloud Console at <a href="https://console.redhat.com">console.redhat.com</a>. Instructions for the <code>rhoas</code> CLI can be found in the appendix.</p>
</div>
<div class="paragraph">
<p><strong>Provision a Kafka instance in OpenShift Streams for Apache Kafka</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Navigate to <a href="https://console.redhat.com">console.redhat.com</a> and log in with your Red Hat account credentials.</p>
</li>
<li>
<p>On the <a href="https://console.redhat.com">console.redhat.com</a> landing page, select <strong>Application and Data Services</strong> from the menu on the left.</p>
</li>
<li>
<p>On the Application Services landing page, select <strong>Streams for Apache Kafka → Kafka Instances</strong>.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/console-redhat-com-kafka-instances.png" alt="console redhat com kafka instances">
</div>
</div>
</li>
<li>
<p>On the Kafka Instances overview page, click the <strong>Create Kafka</strong> instance button. Enter a unique name and select the relevant <em>Cloud region</em> for your Kafka instance and click <strong>Create instance</strong>. This starts the provisioning process for your Kafka instance.</p>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>This will create a evaluation Kafka instance, which will remain available for 48 hrs. The Kafka instance comes with some limitations, which are listed in the <strong>Create instance</strong> window. The eval Kafka instance consists of a single broker, while production Kafka brokers have a minimum of 3 brokers.</p>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>The new Kafka instance is listed in the instances table. After a couple of minutes, your instance should be marked as ready.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/console-redhat-com-kafka-instance-ready.png" alt="console redhat com kafka instance ready">
</div>
</div>
</li>
<li>
<p>When the instance <em>Status</em> is <em>Ready</em>, you can start using the Kafka instance. You can use the options icon (three vertical dots) to view, connect to, or delete the instance as needed.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>Normally, when using Streams for Apache Kafka, the next steps would be to create a service account and set up the Access Control List for that service account. However, when using Service Binding to connect applications to the Kafka instance, a service account is created as part of the binding. Once the service account is created, you will need to setup the required permissions for that service account. An alternative is to set up wildcard permissions (valid for all service accounts), but this is generally considered less secure.</p>
</div>
<div class="paragraph">
<p><strong>Create a Kafka Topic in OpenShift Streams for Apache Kafka</strong></p>
</div>
<div class="paragraph">
<p>After you create a Kafka instance, you can create Kafka topics to start producing and consuming messages in your services.</p>
</div>
<div class="paragraph">
<p>The Activity Tracking service sends activity events to a topic name <code>globex.tracking</code>. Additional topics ae required by the recommendation engine, but these topics are created dynamically when the application starts up.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>In the <strong>Kafka Instances</strong> page of the web console, click the name of the Kafka instance that you want to add a topic to.</p>
</li>
<li>
<p>Select the <strong>Topics</strong> tab, click <strong>Create topic</strong>, and follow the guided steps to define the topic details. Click <strong>Next</strong> to complete each step and click <strong>Finish</strong> to complete the setup.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-create-topic.png" alt="rhosak create topic">
</div>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>Topic name</strong>: Enter <code>globex.tracking</code>.</p>
</li>
<li>
<p><strong>Partitions</strong>: Set the number of partitions for this topic. For this workshop, keep the number of partitions to 1.<br>
Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.</p>
</li>
<li>
<p><strong>Message retention</strong>: Set the message retention time and size to the relevant value and increment. The default retention time is set to <code>A week</code> and the retention size to <code>Unlimited</code>. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted. For this workshop you can keep the default values.</p>
</li>
<li>
<p><strong>Replicas</strong>: For this release of Streams for Apache Kafka, the replicas are preconfigured. As the eval Kafka instance consists of only one broker, the number of partition replicas for the topic is set to <code>1</code>, as well as the minimum number of follower replicas that must be in sync with a partition leader. For a production Kafka broker on Streams for Apache Kafka these values will be <code>3</code> and <code>2</code> respectively.<br>
Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.</p>
</li>
</ul>
</div>
</li>
<li>
<p>After you complete the topic setup, the new Kafka topic is listed in the topics table. You can now start producing and consuming messages to and from this topic using services that you connect to this instance.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-topic-created.png" alt="rhosak topic created">
</div>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_binding_applications_to_streams_for_apache_kafka"><a class="anchor" href="#_binding_applications_to_streams_for_apache_kafka"></a><a class="link" href="#_binding_applications_to_streams_for_apache_kafka">1.4.3. Binding applications to Streams for Apache Kafka</a></h4>
<div class="paragraph">
<p>Binding applications to services using Service Binding requires the Service Binding operator to be installed on the OpenShift cluster. To bind more specifically to a OpenShift Streams for Apache Kafka instance, the Red Hat OpenShift Application Services (RHOAS) operator is required. Both operators have been installed on your OpenShift cluster.</p>
</div>
<div class="paragraph">
<p><strong>Connect OpenShift Streams for Apache Kafka</strong></p>
</div>
<div class="paragraph">
<p>In this part of the workshop you connect your OpenShift instance to the Streams for Kafka instance you created previously. This can be done from the Developer perspective on the OpenShift console, or using the <code>rhoas</code> CLI. Instructions for the CLI can be found in the appendix.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>In a browser window, navigate to the console of your OpenShift cluster. Open the <strong>Developer</strong> perspective in the <strong>globex</strong> namespace.</p>
</li>
<li>
<p>In the Developer perspective, navigate to the <strong>+Add</strong> view. Locate the <strong>Developer Catalog</strong> card with the <strong>Managed Services</strong> entry</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/openshift-console-developer-catalog.png" alt="openshift console developer catalog">
</div>
</div>
</li>
<li>
<p>Click the <strong>Managed Services</strong> link. This opens the Managed Services page, which has a card for <strong>Red Hat OpenShift Application Services</strong>.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/openshift-console-application-services.png" alt="openshift console application services">
</div>
</div>
</li>
<li>
<p>In order to discover the managed services you are entitled to, you need to unlock the functionality with a token obtained from <a href="https://console.redhat.com">console.redhat.com</a>.<br>
Open a new browser tab and navigate to <a href="https://console.redhat.com/openshift/token">console.redhat.com/openshift/token</a>. Click on <strong>Load token</strong> in the <strong>Connect with offline token</strong> box. Copy the generated API token.</p>
</li>
<li>
<p>Go back to the browser tab with the OpenShift console, and click the <strong>Red Hat OpenShift Application Services</strong> card. Paste the API token value in the <strong>API Token</strong> field. Click <strong>Connect</strong>.<br>
You are redirected back to the <strong>Managed Services</strong> page, which shows now a card for <strong>Red Hat OpenShift Streams for Apache Kafka</strong>.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/openshift-console-rhosak.png" alt="openshift console rhosak">
</div>
</div>
</li>
<li>
<p>Click the <strong>Red Hat OpenShift Streams for Apache Kafka</strong> card, and click <strong>Connect</strong>. This opens a page which shows the Kafka instances that you can connect to. Select the entry corresponding to the Kafka instance you created previously. Click <strong>Next</strong></p>
<div class="imageblock">
<div class="content">
<img src="_images/04/openshift-console-rhosak-connect.png" alt="openshift console rhosak connect">
</div>
</div>
</li>
<li>
<p>You are redirected to the <strong>Topology View</strong> of the Developer perspective, which shows now an entry for the managed Kafka instance.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/openshift-console-topology-rhosak.png" alt="openshift console topology rhosak">
</div>
</div>
</li>
<li>
<p>The entry is backed by a <code>KafkaConnection</code> custom resource created by the OpenShift Application Services operator. To see the details of the KafkaConnection resource, click on the resource in the Topology view, and in the Details window, select <strong>Edit KafkaConnection</strong> to see the YAML structure of the custom resource.<br>
Notice that the YAML structure contains the bootstrap URL to the Kafka broker, as well as a reference to a secret containing the data of a service account, named <code>rh-cloud-services-service-account</code>.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Set Permissions for a Service Account</strong></p>
</div>
<div class="paragraph">
<p>As part of connecting to the managed Kafka instance, a service account is created. This is the service account that will be used by the Activity Tracking and Recommendation Engine services to actually connect to the managed Kafka instance. To make this work, the service account needs permissions, in particular the service account needs to be able to consume from topics, produce to topics and create new topics.</p>
</div>
<div class="paragraph">
<p>Setting permissions in the Access Control List of a Streams for Apache Kafka can be done in the <a href="https://console.redhat.com">console.redhat.com</a> console, or using the <code>rhoas</code> CLI. Instructions for the CLI can be found in the appendix.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Navigate to the <strong>Application and Data Services</strong> page of the <a href="https://console.redhat.com">console.redhat.com</a> console.</p>
</li>
<li>
<p>On the <strong>Service Accounts</strong> page, check that a service account was created by the OpenShift Application Services operator. Look for a service account with a name like <code>rhoas-operator-xxx</code>.</p>
</li>
<li>
<p>Navigate to the <strong>Streams for Apache Kafka &#8594; Kafka instances</strong> page and open the page for your Kafka instance.</p>
</li>
<li>
<p>Click the <strong>Access</strong> tab to view the current ACL for this instance.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-default-access.png" alt="rhosak default access">
</div>
</div>
</li>
<li>
<p>Click <strong>Manage access</strong>, use the <strong>Account</strong> drop-down menu to select the service account that was created by the OpenShift Application Services operator, and click <strong>Next</strong>.</p>
</li>
<li>
<p>Under <strong>Assign Permissions</strong>, use the drop-down menus to set the permissions shown in the following table for this service account.<br>
Select the <strong>Consume from a topic</strong> and <strong>Produce to a topic</strong> from the <strong>Task-based permission</strong> possibilities. Set the topic and consumer group names to <code>is</code> and <code>*</code>.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-manage-access.png" alt="rhosak manage access">
</div>
</div>
<div class="paragraph">
<p>Click <strong>Save</strong>.</p>
</div>
<div class="paragraph">
<p>The ACL list for the service account should look like:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-access-serviceaccount.png" alt="rhosak access serviceaccount">
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Bind applications to Streams for Apache Kafka</strong></p>
</div>
<div class="paragraph">
<p>You can now bind the Activity Tracking Service and Recommendation Engine to the OpenShift Streams for Apache instance. Through Service Binding the connection details are injected into the application pods. Service Binding to a managed Kafka instance can be done on the Topology view of OpenShift console, or through the <code>rhoas</code> CLI. The instructions for the <code>rhoas</code> CLI can be found in the appendix.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Navigate to the <strong>Topology</strong> view of the OpenShift console in the <strong>globex</strong> namespace.</p>
</li>
<li>
<p>Hover over the <strong>activity-tracking</strong> deployment, and grab the arrow that appears. Drag the arrow to the <strong>KafkaConnection</strong> icon. When reaching the KafkaConnection icon, a text box <code>Create Service Binding</code> appears. Release the arrow. Click <strong>Create</strong> in the <strong>Create Service Binding</strong> pop-up window. The Activity Tracking deployment and the KafkaConnection icon are now connected with a solid black arrow.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-service-binding.png" alt="rhosak service binding">
</div>
</div>
</li>
<li>
<p>Click on the activity-tracking deployment to open the details window, and click on the deployment name to open the full details of the Deployment. Notice that the service binding occurs by injecting a secret into the pod:</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/service-binding-secret.png" alt="service binding secret">
</div>
</div>
</li>
<li>
<p>Scale the activity-tracking deployment to 1 replica.</p>
</li>
<li>
<p>Check the logs of the activity-tracking pod, and notice that the pod successfully connects to the Kafka broker instance.</p>
<div class="listingblock">
<div class="content">
<pre>exec java -Dquarkus.http.host=0.0.0.0 -Djava.util.logging.manager=org.jboss.logmanager.LogManager -XX:+ExitOnOutOfMemoryError -cp . -jar /deployments/quarkus-run.jar
__  ____  __  _____   ___  __ ____  ______
 --/ __ \/ / / / _ | / _ \/ //_/ / / / __/
 -/ /_/ / /_/ / __ |/ , _/ ,&lt; / /_/ /\ \
--\___\_\____/_/ |_/_/|_/_/|_|\____/___/
2022-05-23 15:26:40,829 INFO  [org.apa.kaf.com.sec.aut.AbstractLogin] (main) Successfully logged in.
2022-05-23 15:26:41,061 INFO  [io.sma.rea.mes.kafka] (main) SRMSG18258: Kafka producer kafka-producer-tracking-event, connected to Kafka brokers 'globex-ca-m-q-mtp---qgalcrg.bf2.kafka.rhcloud.com:443', is configured to write records to 'globex.tracking'
2022-05-23 15:26:41,363 INFO  [io.quarkus] (main) activity-tracking-service 1.0.0-SNAPSHOT on JVM (powered by Quarkus 2.7.4.Final) started in 2.427s. Listening on: http://0.0.0.0:8080
2022-05-23 15:26:41,364 INFO  [io.quarkus] (main) Profile prod activated.
2022-05-23 15:26:41,364 INFO  [io.quarkus] (main) Installed features: [cdi, kafka-client, resteasy-reactive, smallrye-context-propagation, smallrye-health, smallrye-reactive-messaging, smallrye-reactive-messaging-kafka, vertx]</pre>
</div>
</div>
</li>
<li>
<p>Repeat the same procedure for the <strong>recommendation-engine</strong> deployment. Once the service binding created, scale the deployment to 1 pod.</p>
</li>
<li>
<p>Once the recommendation-engine is up and running, check in the <a href="https://console.redhat.com">console.redhat.com</a> console that a number of new topics have been created:</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-kafka-streams-topics.png" alt="rhosak kafka streams topics">
</div>
</div>
<div class="paragraph">
<p>Those are the topics created by the Kafka Streams topology in the Recommendation Engine to calculate the top featured products based on activity events.</p>
</div>
</li>
</ol>
</div>
</div>
<div class="sect3">
<h4 id="_testing_the_globex_coolstuff_application"><a class="anchor" href="#_testing_the_globex_coolstuff_application"></a><a class="link" href="#_testing_the_globex_coolstuff_application">1.4.4. Testing the Globex Coolstuff application</a></h4>
<div class="paragraph">
<p>Now that the Activity Tracking and Recommendation Engine apps are up and running, we can test the generation of activity events and the calculation of the top featured products.</p>
</div>
<div class="paragraph">
<p>The deployment topology for the workshop includes an activity simulator service which will generate a number of activity events randomly distributed over a list of products. These activity events are sent to the Activity Tracking service and transformed into Kafka messages in the <code>globex.tracking</code> topic. These messages are consumed by the Recommendation Engine app to calculate the top featured products.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>In the OpenShift console, locate the route for the <strong>activity-tracking-simulator</strong> deployment.</p>
</li>
<li>
<p>Open a browser tab pointing to the application, and navigate to the <code>q/swagger-ui</code> path. This opens a Swagger UI page which allows you to use the REST API of the application. The REST application has only one operation, <code>POST /simulate</code>.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/activity-tracking-simulator-swagger-ui.png" alt="activity tracking simulator swagger ui">
</div>
</div>
</li>
<li>
<p>Generate a number activities. Set <code>count</code> to any value between 100 and 1000.</p>
</li>
<li>
<p>OpenShift Streams for Apache Kafka has a message viewer functionality that allows you to inspect the contents of messages in a topic.<br>
Navigate to <a href="https://console.redhat.com">console.redhat.com</a>, select your Kafka instance and in the instance window select the <strong>Topics</strong> tab. Click on the <code>globex.tracking</code> topic, and select the messages tab. Notice the activity event messages, with a JSON payload:</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-messages-tracking.png" alt="rhosak messages tracking">
</div>
</div>
</li>
<li>
<p>The featured product list calculated by the Recommendation Engine is produced to the <code>globex.recommendation-product-score-aggregated-changelog</code> topic. The list is recalculated roughly every 10 seconds as long as activity events are produced. Every calculation produces a message to the changelog topic. The last message in the topic represents the latest top featured list.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/rhosak-messages-aggregated-changelog.png" alt="rhosak messages aggregated changelog">
</div>
</div>
</li>
<li>
<p>In a browser window, navigate to the home page of the Globex Coolstuff web application. Notice that the home page now shows a list of featured products.</p>
<div class="imageblock">
<div class="content">
<img src="_images/04/globex-coolstuff-home-page-featured.png" alt="globex coolstuff home page featured">
</div>
</div>
<div class="paragraph">
<p>Also, the product page now shows a banner with the featured products.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/04/globex-coolstuff-product-page-featured.png" alt="globex coolstuff product page featured">
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>Congratulations! You reached the end of this part of the workshop, in which you added event streaming capabilities to the Globex Coolstuff application, using the OpenShift Streams for Apache Kafka managed cloud service, and Service Binding to connect your apps the the Kafka instance.</p>
</div>
</div>
<div class="sect3">
<h4 id="_appendix_use_the_rhoas_cli"><a class="anchor" href="#_appendix_use_the_rhoas_cli"></a><a class="link" href="#_appendix_use_the_rhoas_cli">Appendix: Use the <code>rhoas</code> CLI</a></h4>
<div class="paragraph">
<p>If you prefer to use the <code>rhoas</code> CLI to provision and configure the OpenShift Streams for Apache Kafka instance, and to bind your applications to the Kafka instance using Service Binding, you can follow the following instructions:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Install the <code>rhoas</code> CLI</p>
<div class="ulist">
<ul>
<li>
<p>Obtain the latest release of the <code>rhoas</code> CLI archive for your operating system from the <a href="https://github.com/redhat-developer/app-services-cli/releases/latest">Red Hat OpenShift Application Services CLI releases</a> page on GitHub.</p>
</li>
<li>
<p>Install the package (or extract the archive), and add the <code>rhoam</code> executable to your path.</p>
</li>
<li>
<p>Check the version of the CLI</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas version</code></pre>
</div>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">rhoas version 0.42.2</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Login into Red Hat Application Services</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas login</code></pre>
</div>
</div>
<div class="paragraph">
<p>This initiates a browser based login. Log in using your Red Hat Account credentials.</p>
</div>
</li>
<li>
<p>Provision an evaluation Kafka instance:</p>
<div class="ulist">
<ul>
<li>
<p>Provision the instance:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas kafka create --name globex --region us-east-1</code></pre>
</div>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">{
  "cloud_provider": "aws",
  "created_at": "2022-05-23T17:20:03.700415552Z",
  "href": "/api/kafkas_mgmt/v1/kafkas/ca5s4gjtq6jlcbnumh5g",
  "id": "ca5s4gjtq6jlcbnumh5g",
  "instance_type": "developer",
  "kafka_storage_size": "10Gi",
  "kind": "Kafka",
  "multi_az": false,
  "name": "globex",
  "owner": "rh-bu-cloudservices-tmm",
  "reauthentication_enabled": true,
  "region": "us-east-1",
  "status": "accepted",
  "updated_at": "2022-05-23T17:20:03.700415552Z"
}</code></pre>
</div>
</div>
</li>
<li>
<p>To check the status of the kafka instance:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas status</code></pre>
</div>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Service Context Name:   default
Context File Location:  /home/bernard/.config/rhoas/contexts.json

  Kafka
  -----------------------------------------------------------------------------
  ID:                     ca5s4gjtq6jlcbnumh5g
  Name:                   globex
  Status:                 ready
  Bootstrap URL:          globex-ca-s-gjtq-jlcbnumh-g.bf2.kafka.rhcloud.com:443</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Create a Kafka topic:</p>
<div class="ulist">
<ul>
<li>
<p>Create the topic:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas kafka topic create --name globex.tracking --partitions 1</code></pre>
</div>
</div>
</li>
<li>
<p>Verify the topics:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas kafka topic list</code></pre>
</div>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">  NAME              PARTITIONS   RETENTION TIME (MS)   RETENTION SIZE (BYTES)
 ----------------- ------------ --------------------- ------------------------
  globex.tracking            1   604800000             -1 (Unlimited)</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Connect Streams for Apache Kafka instance.</p>
<div class="ulist">
<ul>
<li>
<p>Before starting, make sure that you are connected to your OpenShift cluster using the <code>oc</code> CLI.</p>
</li>
<li>
<p>To connect your Kafka instance to your project, execute the following command in the terminal:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas cluster connect -n globex</code></pre>
</div>
</div>
</li>
<li>
<p>You are asked to select the type of service you want to connect. Select <strong>kafka</strong> and press <code>enter</code>.</p>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">? Select type of service  [Use arrows to move, type to filter]
&gt; kafka
  service-registry</code></pre>
</div>
</div>
</li>
<li>
<p>The CLI will prints the <strong>Connection Details</strong> and asks you to confirm. Type <code>y</code> and press <code>enter</code> to continue.</p>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">? Select type of service kafka
This command will link your cluster with Cloud Services by creating custom resources and secrets.
In case of problems please execute "rhoas cluster status" to check if your cluster is properly configured

Connection Details:

Service Type:                   kafka
Service Name:                   globex
Kubernetes Namespace:           globex
Service Account Secret:         rh-cloud-services-service-account

? Do you want to continue? (y/N)</code></pre>
</div>
</div>
</li>
<li>
<p>You will be asked to provide a token, which can be retrieved from <a href="https://console.redhat.com/openshift/token">console.redhat.com/openshift/token</a>. Navigate to this URL, copy the token to your clipboard, and copy it into your terminal. Press <code>enter</code> to continue.</p>
<div class="paragraph">
<p>You should see output similar to this:</p>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">✔️  Token Secret "rh-cloud-services-accesstoken" created successfully
✔️  Service Account Secret "rh-cloud-services-service-account" created successfully

Client ID:     srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d

Make a copy of the client ID to store in a safe place. Credentials won't appear again after closing the terminal.

You will need to assign permissions to service account in order to use it.

You need to separately grant service account access to Kafka by issuing following command

  $ rhoas kafka acl grant-access --producer --consumer --service-account srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d --topic all --group all

✔️  kafka resource "globex" has been created
Waiting for status from kafka resource.
Created kafka can be already injected to your application.

To bind you need to have Service Binding Operator installed:
https://github.com/redhat-developer/service-binding-operator

You can bind kafka to your application by executing "rhoas cluster bind"
or directly in the OpenShift Console topology view.

✔️  Connection to service successful.</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The same command can also be run in a non-interactive way:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas cluster connect -n globex --service-type kafka --service-name globex --token eyJhbGciOiJ...GDC-cTHCwgmxT-nzM -y</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
<li>
<p>To verify that the connection has been successfully created, execute the following oc command:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ oc get KafkaConnection -n globex</code></pre>
</div>
</div>
<div class="paragraph">
<p>This should return a <strong>KafkaConnection</strong> with the name of your Kafka instance.</p>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">NAME        AGE
globex      3m42s</code></pre>
</div>
</div>
</li>
</ul>
</div>
</li>
<li>
<p>Assign permissions to the service account created by the OpenShift Application Services operator:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas kafka acl grant-access --producer --consumer --service-account srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d --topic all --group all -y</code></pre>
</div>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">The following ACL rules will be created:

  PRINCIPAL (7)                                    PERMISSION   OPERATION   DESCRIPTION
 ------------------------------------------------ ------------ ----------- -------------------------
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        describe    topic is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        read        topic is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        read        group is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        write       topic is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        create      topic is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        write       transactional-id is "*"
  srvc-acct-553dd8d3-e461-411d-a76c-7769bbb5c45d   allow        describe    transactional-id is "*"

✔️  ACLs successfully created in the Kafka instance "globex"</code></pre>
</div>
</div>
</li>
<li>
<p>Bind an application to a Streams for Apache Kafka instance.</p>
<div class="ulist">
<ul>
<li>
<p>Execute the following command:</p>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas cluster bind -n globex</code></pre>
</div>
</div>
</li>
<li>
<p>You are asked to select the application you want to connect to. Select <strong>activity-tracking</strong> and press <code>enter</code>. (When repeating for the second application, select <strong>recommendation-engine</strong>)</p>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Looking for Deployment resources. Use --deployment-config flag to look for deployment configs
? Please select application you want to connect with  [Use arrows to move, type to filter]
&gt; activity-tracking
  activity-tracking-simulator
  catalog-database
  catalog-service
  globex-ui
  inventory-database
  inventory-service
  recommendation-engine</code></pre>
</div>
</div>
</li>
<li>
<p>You are asked to select the type of service you want to connect. Select <strong>kafka</strong> and press <code>enter</code>.</p>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Looking for Deployment resources. Use --deployment-config flag to look for deployment configs
? Please select application you want to connect with activity-tracking
? Select type of service  [Use arrows to move, type to filter]
&gt; kafka
  service-registry</code></pre>
</div>
</div>
</li>
<li>
<p>The CLI asks you to confirm. Type <code>y</code> and press <code>enter</code> to continue.</p>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Looking for Deployment resources. Use --deployment-config flag to look for deployment configs
? Please select application you want to connect with activity-tracking
? Select type of service kafka
Binding "globex" with "activity-tracking" app
? Do you want to continue? (y/N)</code></pre>
</div>
</div>
<div class="paragraph">
<p>The CLI produces the following output:</p>
</div>
<div class="listingblock console-output">
<div class="content">
<pre class="highlightjs highlight"><code class="language-text hljs" data-lang="text">Using ServiceBinding Operator to perform binding
✔️  Binding globex with activity-tracking app succeeded</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>The command can also be run in a non-interactive way:</p>
</div>
<div class="listingblock console-input">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash">$ rhoas cluster bind -n globex --app-name activity-tracking --service-type kafka --service-name globex -y
$ rhoas cluster bind -n globex --app-name recommendation-engine --service-type kafka --service-name globex -y</code></pre>
</div>
</div>
</td>
</tr>
</table>
</div>
</li>
</ul>
</div>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="03-demo.html" class="query-params-link">3. See the Solution in Action</a></span>
</nav>
</article>
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
  </div>
</main>
</div>
<footer class="footer">
  <img
          src="../../_/img/app-services-logo.png" height="40px" alt="Cloud Native Architecture Solution Patterns"  href="https://redhat.com" ></a>
</footer><script src="../../_/js/vendor/clipboard.js"></script>
<script src="../../_/js/site.js"></script>
<script async src="../../_/js/vendor/highlight.js"></script>
  </body>
</html>
